{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51rEXGxW7Fmn",
        "outputId": "d93831cd-4a44-40fe-cbb4-0a43c449f5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "<ipython-input-4-17cf89a705bf>:21: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = tagger.evaluate(test_sents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6854075551099996\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           .       1.00      0.66      0.80     29083\n",
            "         ADJ       0.91      0.58      0.71      9855\n",
            "         ADP       0.94      0.63      0.76     18434\n",
            "         ADV       0.90      0.67      0.77     10299\n",
            "        CONJ       0.99      0.64      0.78      5974\n",
            "         DET       0.27      0.98      0.42     20030\n",
            "        NOUN       0.97      0.55      0.70     34030\n",
            "         NUM       0.91      0.71      0.80      1072\n",
            "        PRON       0.98      0.80      0.88     13784\n",
            "         PRT       0.91      0.67      0.77      6513\n",
            "        VERB       0.98      0.70      0.82     32291\n",
            "           X       0.73      0.04      0.08       181\n",
            "\n",
            "    accuracy                           0.69    181546\n",
            "   macro avg       0.87      0.64      0.69    181546\n",
            "weighted avg       0.89      0.69      0.73    181546\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[19231     0     0     0     0  9851     0     0     0     0     0     1]\n",
            " [    0  5705     4   312     0  3679    93     0     0    15    47     0]\n",
            " [    0    14 11676   283    15  6180     5     0    15   230    16     0]\n",
            " [    0   248   178  6874    29  2734    27     0     1   198    10     0]\n",
            " [    0     0     0     3  3834  2137     0     0     0     0     0     0]\n",
            " [    0     0   156    42     5 19584     0     2   241     0     0     0]\n",
            " [    0   226     1    22     0 14567 18865    73     0     5   269     2]\n",
            " [    0     0     0     0     0   298    16   758     0     0     0     0]\n",
            " [    0     0    19     2     0  2750     5     0 11007     1     0     0]\n",
            " [    0     7   385    94     0  1640    30     0     1  4344    12     0]\n",
            " [    0    37    32    36     0  9168   470     0     0     1 22547     0]\n",
            " [    0     0     0     0     0   161     9     0     0     0     3     8]]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk.tag import hmm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "sentences = brown.tagged_sents(tagset='universal')\n",
        "train_size = int(0.8 * len(sentences))\n",
        "train_sents = sentences[:train_size]\n",
        "test_sents = sentences[train_size:]\n",
        "\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "tagger = trainer.train_supervised(train_sents)\n",
        "\n",
        "accuracy = tagger.evaluate(test_sents)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "predicted_tags = [tag for sent in test_sents for _, tag in tagger.tag([word for word, _ in sent])]\n",
        "true_tags = [tag for sent in test_sents for _, tag in sent]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_tags, predicted_tags))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_tags, predicted_tags))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "teOowR7M7Gh1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}